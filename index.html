<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>3D Road Assistant</title>
<style>
body, html { margin:0; padding:0; overflow:hidden; background:black; font-family:sans-serif; }
#canvas { position:absolute; top:0; left:0; width:100%; height:100%; }
.ui-overlay {
  position:absolute; top:10px; left:10px; z-index:2;
  background:rgba(255,255,255,0.8); padding:10px; border-radius:10px;
  box-shadow:0 2px 10px rgba(0,0,0,0.3);
  color:black;
}
button { margin-top:10px; padding:5px 10px; font-size:14px; }
</style>
</head>
<body>
<canvas id="canvas"></canvas>
<div class="ui-overlay">
  <h3>3D Road Assistant</h3>
  <p>Detects road lanes and cars; self-learning mode enabled.</p>
  <button id="downloadData">Download Training Data</button>
</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.9.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
<script async src="https://docs.opencv.org/4.8.0/opencv.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/howler/2.2.3/howler.min.js"></script>

<script>
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
canvas.width = window.innerWidth;
canvas.height = window.innerHeight;

// Camera setup
const video = document.createElement('video');
video.autoplay = true;
video.muted = true;
video.playsInline = true;

navigator.mediaDevices.getUserMedia({ video: { facingMode:"environment" } })
  .then(stream => video.srcObject = stream);

// Alarm
const beep = new Howl({ src:['https://actions.google.com/sounds/v1/alarms/beep_short.ogg'] });

// Load object detection
let model;
cocoSsd.load().then(m => { model = m; detectFrame(); });

// Training data
const trainingData = [];

// Draw straight lane lines
function detectLanes(frame){
  ctx.strokeStyle = 'lime';
  ctx.lineWidth = 5;

  // Two straight lines: left and right lanes
  const margin = 150; // distance from canvas edges
  const topOffset = 100; // how high the lanes start at top

  // Left lane
  ctx.beginPath();
  ctx.moveTo(margin, canvas.height);
  ctx.lineTo(margin + 50, topOffset);
  ctx.stroke();

  // Right lane
  ctx.beginPath();
  ctx.moveTo(canvas.width - margin, canvas.height);
  ctx.lineTo(canvas.width - margin - 50, topOffset);
  ctx.stroke();
}

// Draw detected objects
function drawObjects(predictions){
  predictions.forEach(pred => {
    let x = canvas.width/2 + (pred.bbox[0]-video.videoWidth/2)/2;
    let y = canvas.height - pred.bbox[1];
    let width = pred.bbox[2]/video.videoWidth*canvas.width/4;
    let height = pred.bbox[3]/video.videoHeight*canvas.height/4;

    // Car icon
    if(pred.class==='car'||pred.class==='truck'){
      ctx.fillStyle='red';
      ctx.fillRect(x-width/2, y-height/2, width, height);
    } else if(pred.class==='person'||pred.class==='dog'||pred.class==='cat'){
      ctx.fillStyle='orange';
      ctx.beginPath();
      ctx.arc(x,y,Math.max(width,height)/2,0,Math.PI*2);
      ctx.fill();
    } else {
      ctx.fillStyle='blue';
      ctx.beginPath();
      ctx.arc(x,y,10,0,Math.PI*2);
      ctx.fill();
    }

    // Proximity alarm
    if(pred.bbox[3] > 150) beep.play();
  });
}

// Save frames & predictions
function saveTraining(frame, predictions){
  trainingData.push({ frame: Array.from(frame.data), predictions });
}

// Download training data
document.getElementById('downloadData').addEventListener('click',()=>{
  const blob = new Blob([JSON.stringify(trainingData)], {type:'application/json'});
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = 'trainingData.json';
  a.click();
  URL.revokeObjectURL(url);
});

// Main loop
function detectFrame(){
  if(!model || !cv || !cv.Mat) return requestAnimationFrame(detectFrame);

  // Draw video frame
  ctx.drawImage(video,0,0,canvas.width,canvas.height);
  const frame = ctx.getImageData(0,0,canvas.width,canvas.height);

  // Lane detection
  detectLanes(frame);

  // Object detection
  model.detect(video).then(predictions=>{
    drawObjects(predictions);
    saveTraining(frame, predictions);
    requestAnimationFrame(detectFrame);
  });
}
</script>
</body>
</html>
