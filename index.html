<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>3D Road Assistant</title>
<style>
body, html { margin:0; padding:0; overflow:hidden; background:black; font-family:sans-serif; }
#canvas { position:absolute; top:0; left:0; width:100%; height:100%; }
.ui-overlay {
  position:absolute; top:10px; left:10px; z-index:2;
  background:rgba(255,255,255,0.8); padding:10px; border-radius:10px;
  box-shadow:0 2px 10px rgba(0,0,0,0.3);
  color:black;
}
button {
  margin-top:10px; padding:5px 10px; font-size:14px;
}
</style>
</head>
<body>
<canvas id="canvas"></canvas>
<div class="ui-overlay">
  <h3>3D Road Assistant</h3>
  <p>Detects road lanes and cars; self-learning mode enabled.</p>
  <button id="downloadBtn">Download Training Data</button>
</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.9.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
<script async src="https://docs.opencv.org/4.8.0/opencv.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/howler/2.2.3/howler.min.js"></script>

<script>
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
canvas.width = window.innerWidth;
canvas.height = window.innerHeight;

// Camera setup
const video = document.createElement('video');
video.autoplay = true;
video.muted = true;
video.playsInline = true;

navigator.mediaDevices.getUserMedia({ video: { facingMode:"environment" } })
  .then(stream => video.srcObject = stream);

// Alarm
const beep = new Howl({ src:['https://actions.google.com/sounds/v1/alarms/beep_short.ogg'] });

// Load object detection
let model;
cocoSsd.load().then(m => { model = m; detectFrame(); });

// OpenCV lane detection
function detectLanes(frame){
  let src = cv.matFromImageData(frame);
  let gray = new cv.Mat();
  let edges = new cv.Mat();
  cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
  cv.GaussianBlur(gray, gray, new cv.Size(5,5), 0);
  cv.Canny(gray, edges, 50, 150);

  // Hough lines
  let lines = new cv.Mat();
  cv.HoughLinesP(edges, lines, 1, Math.PI/180, 50, 50, 150);

  ctx.strokeStyle = 'lime';
  ctx.lineWidth = 5;
  for(let i=0; i<lines.rows; i++){
    let [x1, y1, x2, y2] = lines.data32S.slice(i*4, i*4+4);
    ctx.beginPath();
    ctx.moveTo(x1 * canvas.width/video.videoWidth, y1 * canvas.height/video.videoHeight);
    ctx.lineTo(x2 * canvas.width/video.videoWidth, y2 * canvas.height/video.videoHeight);
    ctx.stroke();
  }

  src.delete(); gray.delete(); edges.delete(); lines.delete();
}

// Draw detected objects
function drawObjects(predictions){
  predictions.forEach(pred => {
    let x = canvas.width/2 + (pred.bbox[0]-video.videoWidth/2)/2;
    let y = canvas.height - pred.bbox[1];
    let width = pred.bbox[2]/video.videoWidth*canvas.width/4;
    let height = pred.bbox[3]/video.videoHeight*canvas.height/4;

    // Car icon
    if(pred.class==='car'||pred.class==='truck'){
      ctx.fillStyle='red';
      ctx.fillRect(x-width/2, y-height/2, width, height);
    } else if(pred.class==='person'||pred.class==='dog'||pred.class==='cat'){
      ctx.fillStyle='orange';
      ctx.beginPath();
      ctx.arc(x,y,Math.max(width,height)/2,0,Math.PI*2);
      ctx.fill();
    } else {
      ctx.fillStyle='blue';
      ctx.beginPath();
      ctx.arc(x,y,10,0,Math.PI*2);
      ctx.fill();
    }

    // Proximity alarm
    if(pred.bbox[3] > 150) beep.play();
  });
}

// Self-training: save frames & predictions
const trainingData = [];
function saveTraining(frame, predictions){
  // Convert frame to base64 for easier download
  const tempCanvas = document.createElement('canvas');
  tempCanvas.width = frame.width;
  tempCanvas.height = frame.height;
  tempCanvas.getContext('2d').putImageData(frame, 0, 0);
  const imgBase64 = tempCanvas.toDataURL('image/png');
  trainingData.push({ frame: imgBase64, predictions });
}

// Main loop
function detectFrame(){
  if(!model || !cv || !cv.Mat) return requestAnimationFrame(detectFrame);

  ctx.drawImage(video,0,0,canvas.width,canvas.height);
  const frame = ctx.getImageData(0,0,canvas.width,canvas.height);

  detectLanes(frame);

  model.detect(video).then(predictions=>{
    drawObjects(predictions);
    saveTraining(frame, predictions); // store for self-training
    requestAnimationFrame(detectFrame);
  });
}

// Download training data
document.getElementById('downloadBtn').addEventListener('click', ()=>{
  const blob = new Blob([JSON.stringify(trainingData)], {type:'application/json'});
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = 'training_data.json';
  a.click();
  URL.revokeObjectURL(url);
});
</script>
</body>
</html>
