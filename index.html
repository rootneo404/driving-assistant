<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>3D Road Assistant</title>
<style>
body, html { margin:0; padding:0; overflow:hidden; background:white; font-family:sans-serif; }
#canvas { position:absolute; top:0; left:0; width:100%; height:100%; background:white; }
.ui-overlay {
  position:absolute; top:10px; left:10px; z-index:2;
  background:rgba(255,255,255,0.8); padding:10px; border-radius:10px;
  box-shadow:0 2px 10px rgba(0,0,0,0.3);
  color:black;
}
#saveTrainingBtn {
  position:absolute; top:150px; left:10px; z-index:3;
  padding:10px; border-radius:5px; border:none; background:limegreen;
  color:white; font-weight:bold; cursor:pointer;
}
</style>
</head>
<body>
<canvas id="canvas"></canvas>
<div class="ui-overlay">
  <h3>3D Road Assistant</h3>
  <p>Detects road lanes and cars; self-learning mode enabled.</p>
</div>
<button id="saveTrainingBtn">Save Training Data</button>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.9.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
<script async src="https://docs.opencv.org/4.8.0/opencv.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/howler/2.2.3/howler.min.js"></script>

<script>
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
canvas.width = window.innerWidth;
canvas.height = window.innerHeight;

// Camera setup (for detection only)
const video = document.createElement('video');
video.autoplay = true;
video.muted = true;
video.playsInline = true;

navigator.mediaDevices.getUserMedia({ video: { facingMode:"environment" } })
  .then(stream => { video.srcObject = stream; })
  .catch(err => alert("Camera error: " + err));

// Alarm
const beep = new Howl({ src:['https://actions.google.com/sounds/v1/alarms/beep_short.ogg'] });

// Lane detection smoothing
let leftLane = null;
let rightLane = null;
const laneHistory = { left: [], right: [], max: 5 };

// Self-learning storage
const trainingData = [];

// Wait for OpenCV.js
function onOpenCvReady() {
    console.log("OpenCV.js is ready");

    cocoSsd.load().then(m => { 
        model = m; 
        video.addEventListener('loadeddata', () => detectFrame());
    });
}

// Lane detection function (two lanes, smoothing, straight if unsure)
function detectLanes(frame){
  if(!cv || !cv.Mat) return;

  let src = cv.matFromImageData(frame);
  let gray = new cv.Mat();
  let edges = new cv.Mat();
  cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
  cv.GaussianBlur(gray, gray, new cv.Size(5,5), 0);
  cv.Canny(gray, edges, 50, 150);

  // Region of interest (bottom 50% of frame)
  let mask = new cv.Mat.zeros(edges.rows, edges.cols, edges.type());
  let pts = cv.matFromArray(4,1,cv.CV_32SC2,[
    0, edges.rows,
    edges.cols, edges.rows,
    edges.cols, edges.rows*0.5,
    0, edges.rows*0.5
  ]);
  cv.fillPoly(mask, [pts], [255,255,255,255]);
  cv.bitwise_and(edges, mask, edges);

  // Hough lines
  let lines = new cv.Mat();
  cv.HoughLinesP(edges, lines, 1, Math.PI/180, 50, 50, 50);

  let leftLines = [], rightLines = [];
  for(let i=0;i<lines.rows;i++){
    let [x1,y1,x2,y2] = lines.data32S.slice(i*4,i*4+4);
    let slope = (y2 - y1) / (x2 - x1 + 0.0001);
    if(Math.abs(slope)<0.3) continue;
    if(slope<0) leftLines.push([x1,y1,x2,y2]);
    else rightLines.push([x1,y1,x2,y2]);
  }

  function averageLine(lines){
    if(lines.length===0) return null;
    let x1=0,y1=0,x2=0,y2=0;
    lines.forEach(l=>{ x1+=l[0]; y1+=l[1]; x2+=l[2]; y2+=l[3]; });
    return [x1/lines.length, y1/lines.length, x2/lines.length, y2/lines.length];
  }

  leftLane = averageLine(leftLines) || leftLane || [0,edges.rows,edges.cols*0.25,edges.rows*0.5];
  rightLane = averageLine(rightLines) || rightLane || [edges.cols,edges.rows,edges.cols*0.75,edges.rows*0.5];

  // Smooth lanes
  if(leftLane){
    laneHistory.left.push(leftLane);
    if(laneHistory.left.length>laneHistory.max) laneHistory.left.shift();
    leftLane = laneHistory.left.reduce((acc,l)=>acc.map((v,i)=>v+l[i]),[0,0,0,0]).map(v=>v/laneHistory.left.length);
  }
  if(rightLane){
    laneHistory.right.push(rightLane);
    if(laneHistory.right.length>laneHistory.max) laneHistory.right.shift();
    rightLane = laneHistory.right.reduce((acc,l)=>acc.map((v,i)=>v+l[i]),[0,0,0,0]).map(v=>v/laneHistory.right.length);
  }

  // Draw lanes
  ctx.strokeStyle='lime';
  ctx.lineWidth=5;
  [leftLane,rightLane].forEach(l=>{
    if(!l) return;
    ctx.beginPath();
    ctx.moveTo(l[0]*canvas.width/video.videoWidth, l[1]*canvas.height/video.videoHeight);
    ctx.lineTo(l[2]*canvas.width/video.videoWidth, l[3]*canvas.height/video.videoHeight);
    ctx.stroke();
  });

  src.delete(); gray.delete(); edges.delete(); mask.delete(); lines.delete(); pts.delete();
}

// Draw objects
function drawObjects(predictions){
  predictions.forEach(pred=>{
    let x = canvas.width/2 + (pred.bbox[0]-video.videoWidth/2)/2;
    let y = canvas.height - pred.bbox[1];
    let width = pred.bbox[2]/video.videoWidth*canvas.width/4;
    let height = pred.bbox[3]/video.videoHeight*canvas.height/4;

    if(pred.class==='car'||pred.class==='truck'){
      ctx.fillStyle='red';
      ctx.fillRect(x-width/2, y-height/2, width, height);
    } else if(pred.class==='person'||pred.class==='dog'||pred.class==='cat'){
      ctx.fillStyle='orange';
      ctx.beginPath();
      ctx.arc(x,y,Math.max(width,height)/2,0,Math.PI*2);
      ctx.fill();
    } else {
      ctx.fillStyle='blue';
      ctx.beginPath();
      ctx.arc(x,y,10,0,Math.PI*2);
      ctx.fill();
    }

    if(pred.bbox[3]>150) beep.play();
  });
}

// Save training data
function saveTraining(frame, predictions){
  trainingData.push({ frame: frame.data, predictions });
}

// Main loop
function detectFrame(){
  if(!model || !cv || !cv.Mat) return requestAnimationFrame(detectFrame);

  // Clear canvas
  ctx.fillStyle='white';
  ctx.fillRect(0,0,canvas.width,canvas.height);

  // Capture video frame for processing only
  const frameCanvas = document.createElement('canvas');
  frameCanvas.width = video.videoWidth;
  frameCanvas.height = video.videoHeight;
  const frameCtx = frameCanvas.getContext('2d');
  frameCtx.drawImage(video,0,0);
  const frameData = frameCtx.getImageData(0,0,video.videoWidth,video.videoHeight);

  // Detect lanes & objects
  detectLanes(frameData);
  model.detect(video).then(predictions=>{
    drawObjects(predictions);
    saveTraining(frameData, predictions);
    requestAnimationFrame(detectFrame);
  });
}

// Button to save training data
document.getElementById('saveTrainingBtn').addEventListener('click', ()=>{
  if(trainingData.length===0){ alert("No training data collected!"); return; }
  const blob = new Blob([JSON.stringify(trainingData)],{type:"application/json"});
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = "trainingData.json";
  a.click();
  URL.revokeObjectURL(url);
});

// OpenCV ready
window.cv = window.cv||{};
cv['onRuntimeInitialized'] = onOpenCvReady;
</script>
</body>
</html>
